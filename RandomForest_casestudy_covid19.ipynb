{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EvpyI0E7SpNT"
   },
   "source": [
    "## Random Forest\n",
    "\n",
    "Random Forest is an ensemble of Decision Trees. With a few exceptions, a `RandomForestClassifier` has all the hyperparameters of a `DecisionTreeClassifier` (to control how trees are grown), plus all the hyperparameters of a `BaggingClassifier` to control the ensemble itself.\n",
    "\n",
    "The Random Forest algorithm introduces extra randomness when growing trees; instead of searching for the very best feature when splitting a node, it searches for the best feature among a random subset of features. This results in a greater tree diversity, which (once again) trades a higher bias for a lower variance, generally yielding an overall better model. The following `BaggingClassifier` is roughly equivalent to the previous `RandomForestClassifier`. Run the cell below to visualize a single estimator from a random forest model, using the Iris dataset to classify the data into the appropriate species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1NIbktS4yyfVlE2Y4bXMargRbQgbdWTFh"
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7579,
     "status": "ok",
     "timestamp": 1592213046926,
     "user": {
      "displayName": "Andrew Maguire",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaIpd1sqQPWOc9NJXtyl5fYSonikxEZgshlvloAYk=s64",
      "userId": "13447906511017779027"
     },
     "user_tz": -60
    },
    "id": "z_-6xEUFSpNU",
    "outputId": "75184be3-e99c-4c44-a638-824a9ba0b1e9"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "\n",
    "# Model (can also use single decision tree)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=10)\n",
    "\n",
    "# Train\n",
    "model.fit(iris.data, iris.target)\n",
    "# Extract single tree\n",
    "estimator = model.estimators_[5]\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "# Export as dot file\n",
    "export_graphviz(estimator, out_file='tree.dot', \n",
    "                feature_names = iris.feature_names,\n",
    "                class_names = iris.target_names,\n",
    "                rounded = True, proportion = False, \n",
    "                precision = 2, filled = True)\n",
    "\n",
    "# Convert to png using system command (requires Graphviz)\n",
    "#from subprocess import call\n",
    "call(['dot', '-Tpng', 'tree.dot', '-o', 'tree.png', '-Gdpi=600'], shell=True)\n",
    "\n",
    "# Display in jupyter notebook\n",
    "from IPython.display import Image\n",
    "Image(filename = 'tree.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VSnWoCRUSpNY"
   },
   "source": [
    "Notice how each split seperates the data into buckets of similar observations. This is a single tree and a relatively simple classification dataset, but the same method is used in a more complex dataset with greater depth to the trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tJ2aGPMZB5X8"
   },
   "source": [
    "## Coronavirus\n",
    "Coronavirus disease (COVID-19) is an infectious disease caused by a new virus.\n",
    "The disease causes respiratory illness (like the flu) with symptoms such as a cough, fever, and in more severe cases, difficulty breathing. You can protect yourself by washing your hands frequently, avoiding touching your face, and avoiding close contact (1 meter or 3 feet) with people who are unwell. An outbreak of COVID-19 started in December 2019 and at the time of the creation of this project was continuing to spread throughout the world. Many governments recommended only essential outings to public places and closed most business that do not serve food or sell essential items. An excellent [spatial dashboard](https://www.arcgis.com/apps/opsdashboard/index.html#/bda7594740fd40299423467b48e9ecf6) built by Johns Hopkins shows the daily confirmed cases by country. \n",
    "\n",
    "This case study was designed to drive home the important role that data science plays in real-world situations like this pandemic. This case study uses the Random Forest Classifier and a dataset from the South Korean cases of COVID-19 provided on [Kaggle](https://www.kaggle.com/kimjihoo/coronavirusdataset) to encourage research on this important topic. The goal of the case study is to build a Random Forest Classifier to predict the 'state' of the patient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7PrMkSjBQEMZ"
   },
   "source": [
    "First, please load the needed packages and modules into Python. Next, load the data into a pandas dataframe for ease of use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X3EhD-LSB5YI"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime,timedelta\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import ExtraTreesRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CiJQlTK1SpNd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>country</th>\n",
       "      <th>province</th>\n",
       "      <th>city</th>\n",
       "      <th>infection_case</th>\n",
       "      <th>infected_by</th>\n",
       "      <th>contact_number</th>\n",
       "      <th>symptom_onset_date</th>\n",
       "      <th>confirmed_date</th>\n",
       "      <th>released_date</th>\n",
       "      <th>deceased_date</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000000001</td>\n",
       "      <td>male</td>\n",
       "      <td>50s</td>\n",
       "      <td>Korea</td>\n",
       "      <td>Seoul</td>\n",
       "      <td>Gangseo-gu</td>\n",
       "      <td>overseas inflow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>2020-02-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>released</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000000002</td>\n",
       "      <td>male</td>\n",
       "      <td>30s</td>\n",
       "      <td>Korea</td>\n",
       "      <td>Seoul</td>\n",
       "      <td>Jungnang-gu</td>\n",
       "      <td>overseas inflow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-30</td>\n",
       "      <td>2020-03-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>released</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000000003</td>\n",
       "      <td>male</td>\n",
       "      <td>50s</td>\n",
       "      <td>Korea</td>\n",
       "      <td>Seoul</td>\n",
       "      <td>Jongno-gu</td>\n",
       "      <td>contact with patient</td>\n",
       "      <td>2002000001</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-30</td>\n",
       "      <td>2020-02-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>released</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000000004</td>\n",
       "      <td>male</td>\n",
       "      <td>20s</td>\n",
       "      <td>Korea</td>\n",
       "      <td>Seoul</td>\n",
       "      <td>Mapo-gu</td>\n",
       "      <td>overseas inflow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>2020-01-26</td>\n",
       "      <td>2020-01-30</td>\n",
       "      <td>2020-02-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>released</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000000005</td>\n",
       "      <td>female</td>\n",
       "      <td>20s</td>\n",
       "      <td>Korea</td>\n",
       "      <td>Seoul</td>\n",
       "      <td>Seongbuk-gu</td>\n",
       "      <td>contact with patient</td>\n",
       "      <td>1000000002</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>released</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id     sex  age country province         city  \\\n",
       "0  1000000001    male  50s   Korea    Seoul   Gangseo-gu   \n",
       "1  1000000002    male  30s   Korea    Seoul  Jungnang-gu   \n",
       "2  1000000003    male  50s   Korea    Seoul    Jongno-gu   \n",
       "3  1000000004    male  20s   Korea    Seoul      Mapo-gu   \n",
       "4  1000000005  female  20s   Korea    Seoul  Seongbuk-gu   \n",
       "\n",
       "         infection_case infected_by contact_number symptom_onset_date  \\\n",
       "0       overseas inflow         NaN             75         2020-01-22   \n",
       "1       overseas inflow         NaN             31                NaN   \n",
       "2  contact with patient  2002000001             17                NaN   \n",
       "3       overseas inflow         NaN              9         2020-01-26   \n",
       "4  contact with patient  1000000002              2                NaN   \n",
       "\n",
       "  confirmed_date released_date deceased_date     state  \n",
       "0     2020-01-23    2020-02-05           NaN  released  \n",
       "1     2020-01-30    2020-03-02           NaN  released  \n",
       "2     2020-01-30    2020-02-19           NaN  released  \n",
       "3     2020-01-30    2020-02-15           NaN  released  \n",
       "4     2020-01-31    2020-02-24           NaN  released  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url ='PatientInfo.csv'\n",
    "df = pd.read_csv(url)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GUY5Cp2cSpNg"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5165, 14)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oxKUKR_pSpNi"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VarName</th>\n",
       "      <th>NullCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deceased_date</td>\n",
       "      <td>5099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>symptom_onset_date</td>\n",
       "      <td>4475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>contact_number</td>\n",
       "      <td>4374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>infected_by</td>\n",
       "      <td>3819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>released_date</td>\n",
       "      <td>3578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>age</td>\n",
       "      <td>1380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sex</td>\n",
       "      <td>1122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>infection_case</td>\n",
       "      <td>919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>city</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>confirmed_date</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              VarName  NullCount\n",
       "0       deceased_date       5099\n",
       "1  symptom_onset_date       4475\n",
       "2      contact_number       4374\n",
       "3         infected_by       3819\n",
       "4       released_date       3578\n",
       "5                 age       1380\n",
       "6                 sex       1122\n",
       "7      infection_case        919\n",
       "8                city         94\n",
       "9      confirmed_date          3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Counts of null values \n",
    "na_df=pd.DataFrame(df.isnull().sum().sort_values(ascending=False)).reset_index()\n",
    "na_df.columns = ['VarName', 'NullCount']\n",
    "na_df[(na_df['NullCount']>0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NhPtmRWdSpNl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "released    2929\n",
       "isolated    2158\n",
       "deceased      78\n",
       "Name: state, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#counts of response variable values\n",
    "df.state.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "06e0gqMzSpNp"
   },
   "source": [
    " **<font color='teal'> Create a new column named 'n_age' which is the calculated age based on the birth year column.</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DVCW7LBRSpNp"
   },
   "outputs": [],
   "source": [
    "# there is no birth year in this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w9t91IzDSpNr"
   },
   "source": [
    "### Handle Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fm1TjGDhSpNs"
   },
   "source": [
    " **<font color='teal'> Print the number of missing values by column.</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PAtr2t3rSpNs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient_id               0\n",
      "sex                   1122\n",
      "age                   1380\n",
      "country                  0\n",
      "province                 0\n",
      "city                    94\n",
      "infection_case         919\n",
      "infected_by           3819\n",
      "contact_number        4374\n",
      "symptom_onset_date    4475\n",
      "confirmed_date           3\n",
      "released_date         3578\n",
      "deceased_date         5099\n",
      "state                    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I8B5cY19SpNu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5165 entries, 0 to 5164\n",
      "Data columns (total 14 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   patient_id          5165 non-null   int64 \n",
      " 1   sex                 4043 non-null   object\n",
      " 2   age                 3785 non-null   object\n",
      " 3   country             5165 non-null   object\n",
      " 4   province            5165 non-null   object\n",
      " 5   city                5071 non-null   object\n",
      " 6   infection_case      4246 non-null   object\n",
      " 7   infected_by         1346 non-null   object\n",
      " 8   contact_number      791 non-null    object\n",
      " 9   symptom_onset_date  690 non-null    object\n",
      " 10  confirmed_date      5162 non-null   object\n",
      " 11  released_date       1587 non-null   object\n",
      " 12  deceased_date       66 non-null     object\n",
      " 13  state               5165 non-null   object\n",
      "dtypes: int64(1), object(13)\n",
      "memory usage: 565.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zjLpYG_ASpNw"
   },
   "source": [
    " **<font color='teal'> Fill the 'disease' missing values with 0 and remap the True values to 1.</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NHBtVW1ESpNx"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "released    2929\n",
       "isolated    2158\n",
       "deceased      78\n",
       "Name: state, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.state.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fZArBBUhSpNz"
   },
   "source": [
    " **<font color='teal'> Fill null values in the following columns with their mean: 'global_number','birth_year','infection_order','infected_by'and 'contact_number'</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zQdarDx_SpNz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Coy_jYEbSpN2"
   },
   "source": [
    " **<font color='teal'> Fill the rest of the missing values with any method.</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ATJ84cdDSpN2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kGi4NkcbSpN4"
   },
   "source": [
    " **<font color='teal'> Check for any remaining null values.</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "82lVA3vUSpN5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "55CJRFKtSpN7"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PK9Jk8KgSpN9"
   },
   "source": [
    "Remove date columns from the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xIbYDncMSpN9"
   },
   "outputs": [],
   "source": [
    "df = df.drop(['symptom_onset_date','confirmed_date','released_date','deceased_date'],axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RDBxf5ZDB5ZZ"
   },
   "source": [
    "Review the count of unique values by column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PIdCkZ4AB5Zf"
   },
   "outputs": [],
   "source": [
    "print(df.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9oENi5DRB5Zq"
   },
   "source": [
    "Review the percent of unique values by column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_IcO33VsB5Zt"
   },
   "outputs": [],
   "source": [
    "print(df.nunique()/df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rCZHVugqB5Z4"
   },
   "source": [
    "Review the range of values per column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y3zLsGxMB5Z5"
   },
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AEBFq3hmB5aN"
   },
   "source": [
    "### Check for duplicated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s9KGFCpkB5aP"
   },
   "outputs": [],
   "source": [
    "duplicateRowsDF = df[df.duplicated()]\n",
    "duplicateRowsDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8WOrbEk1SpOH"
   },
   "source": [
    "Print the categorical columns and their associated levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8QTm6RuRSpOH"
   },
   "outputs": [],
   "source": [
    "dfo = df.select_dtypes(include=['object'], exclude=['datetime'])\n",
    "dfo.shape\n",
    "#get levels for all variables\n",
    "vn = pd.DataFrame(dfo.nunique()).reset_index()\n",
    "vn.columns = ['VarName', 'LevelsCount']\n",
    "vn.sort_values(by='LevelsCount', ascending =False)\n",
    "vn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a43l6w_uSpOJ"
   },
   "source": [
    "**<font color='teal'> Plot the correlation heat map for the features.</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZRJlPqV5B5e5",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2KtABW0USpOK"
   },
   "source": [
    "**<font color='teal'> Plot the boxplots to check for outliers. </font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uYMmU_szB5fZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Z_NuqkNSpOM"
   },
   "source": [
    "**<font color='teal'> Create dummy features for object type features. </font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0uTSQY_liDHj"
   },
   "source": [
    "### Split the data into test and train subsamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BSkPut0gguds"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# dont forget to define your X and y\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TcrOg3y7gRtG"
   },
   "source": [
    "### Scale data to prep for model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IZL-q-KtAYI6"
   },
   "outputs": [],
   "source": [
    "#scale data\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "# build scaler based on training data and apply it to test data to then also scale the test data\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_scaled=scaler.transform(X_train)\n",
    "X_test_scaled=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZSOICugNSpOR"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from matplotlib import pyplot\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report,confusion_matrix,roc_curve,roc_auc_score\n",
    "from sklearn.metrics import accuracy_score,log_loss\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vzrLoM58SpOT"
   },
   "source": [
    "### Fit Random Forest Classifier\n",
    "The fit model shows an overall accuracy of 80% which is great and indicates our model was effectively able to identify the status of a patients in the South Korea dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b9jQyje3SpOU"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=300, random_state = 1,n_jobs=-1)\n",
    "model_res = clf.fit(X_train_scaled, y_train)\n",
    "y_pred = model_res.predict(X_test_scaled)\n",
    "y_pred_prob = model_res.predict_proba(X_test_scaled)\n",
    "lr_probs = y_pred_prob[:,1]\n",
    "ac = accuracy_score(y_test, y_pred)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print('Random Forest: Accuracy=%.3f' % (ac))\n",
    "\n",
    "print('Random Forest: f1-score=%.3f' % (f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QYdW02QQSpOW"
   },
   "source": [
    "### Create Confusion Matrix Plots\n",
    "Confusion matrices are great ways to review your model performance for a multi-class classification problem. Being able to identify which class the misclassified observations end up in is a great way to determine if you need to build additional features to improve your overall model. In the example below we plot a regular counts confusion matrix as well as a weighted percent confusion matrix. The percent confusion matrix is particulary helpful when you have unbalanced class sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wSWGVZU6SpOW"
   },
   "outputs": [],
   "source": [
    "class_names=['isolated','released','missing','deceased'] # name  of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GjnV5ugJSpOb"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "#plt.savefig('figures/RF_cm_multi_class.png')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "#plt.savefig('figures/RF_cm_proportion_multi_class.png', bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z7PtbV4LSpOc"
   },
   "source": [
    "### Plot feature importances\n",
    "The random forest algorithm can be used as a regression or classification model. In either case it tends to be a bit of a black box, where understanding what's happening under the hood can be difficult. Plotting the feature importances is one way that you can gain a perspective on which features are driving the model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T1xpGOCVSpOc"
   },
   "outputs": [],
   "source": [
    "feature_importance = clf.feature_importances_\n",
    "# make importances relative to max importance\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())[:30]\n",
    "sorted_idx = np.argsort(feature_importance)[:30]\n",
    "\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "print(pos.size)\n",
    "sorted_idx.size\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(pos, X.columns[sorted_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ys_mI5GsSpOe"
   },
   "source": [
    "The popularity of random forest is primarily due to how well it performs in a multitude of data situations. It tends to handle highly correlated features well, where as a linear regression model would not. In this case study we demonstrate the performance ability even with only a few features and almost all of them being highly correlated with each other.\n",
    "Random Forest is also used as an efficient way to investigate the importance of a set of features with a large data set. Consider random forest to be one of your first choices when building a decision tree, especially for multiclass classifications."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "FXGd_NbdB5kn"
   ],
   "name": "RandomForest_casestudy_covid19.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
